# -*- coding: utf-8 -*-
"""IMLO_CW_works.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jQt2K_AlnTSZYpy4APJTVxHN3SAIzg5H
"""

import torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms, datasets
from torch.utils.data import DataLoader
from torchvision.transforms import ToTensor

import matplotlib.pyplot as plt
import numpy as np

from sklearn import datasets
import pandas as pd

Batch_Size = 64
EPOCHS = 50

train_set = torchvision.datasets.CIFAR10("Data", download=True, train=True, transform=transform) #was transform = train_tr
train_loader = torch.utils.data.DataLoader(train_set, batch_size=Batch_Size, shuffle=False)

test_set = torchvision.datasets.CIFAR10("Data", download=True, train=False, transform=transform) # was test_tr
test_loader = torch.utils.data.DataLoader(test_set, batch_size=Batch_Size, shuffle=False)

print(train_set.data.shape)
print(test_set.data.shape)
print(train_set.classes)

mean = train_set.data.mean() / 255
std = train_set.data.std() / 255
print(mean, std)

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

class CIFAR10_nn(nn.Module):
  def __init__(self):
    super(CIFAR10_nn, self).__init__()

    #3 input channels, 32 output feature maps, 3x3 filter size, padding keeps image dimensions the same
    self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)

    #pooling layers reduce image size, takes max value in each 2x2 region
    self.pool = nn.MaxPool2d(2, 2)

    #fully connected layers connect every input to every output
    self.fc1 = nn.Linear(64 * 8 * 8, 512)
    self.fc2 = nn.Linear(512, 10)

    #Dropout randomly turns off 25% of neurons during training
    #--> Prevents nn from memorising the training data
    self.dropout = nn.Dropout(0.25)

  #Defines how data flows through the network
  def forward(self, x):
    #1. 1st conv layer -> reLU activation -> pooling
    x = self.pool(F.relu(self.conv1(x)))
    #2. 2nd conv layer -> reLU activation -> pooling
    x = self.pool(F.relu(self.conv2(x)))
    #3. Flatten 3D feature maps into a 1D vector
    x = x.view(-1, 64 * 8 * 8)
    #4. 1st fully connected layer -> ReLU -> dropout
    x = self.dropout(F.relu(self.fc1(x)))
    #5. Final outout layer
    x = self.fc2(x)
    return x

net = CIFAR10_nn()
print(net)

correct = 0
total = 0

criterion = nn.CrossEntropyLoss()
optimiser = optim.Adam(net.parameters(), lr=0.001)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

for epoch in range(EPOCHS):
  net.train()
  for i, data in enumerate(train_loader, 0):
    inputs, labels = data
    inputs, labels = inputs.to(device), labels.to(device)

    optimiser.zero_grad()
    outputs = net(inputs)
    loss = criterion(outputs, labels)
    loss.backward()
    optimiser.step()

net.eval()  # Set model to evaluation mode
with torch.no_grad():  # No need to track gradients
    for data in test_loader:
        images, labels = data
        images, labels = images.to(device), labels.to(device)
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

accuracy = 100 * correct / total  # Should now be <= 100%
print(f'Test Accuracy: {accuracy:.2f}%')
