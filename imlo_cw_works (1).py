# -*- coding: utf-8 -*-
"""IMLO_CW_works.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jQt2K_AlnTSZYpy4APJTVxHN3SAIzg5H
"""

import torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms, datasets
from torch.utils.data import DataLoader
from torchvision.transforms import ToTensor

import matplotlib.pyplot as plt
import numpy as np

from sklearn import datasets
import pandas as pd

Batch_Size = 64
EPOCHS = 50

train_set = torchvision.datasets.CIFAR10("Data", download-True, train=True, transform=ToTensor())

mean = train_set.data.mean(axis=(0,1,2)) / 255
std = train_set.data.std(axis=(0,1,2)) / 255
print(f"Mean = {mean} Std = {std}")

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

train_set = torchvision.datasets.CIFAR10("Data", download=True, train=True, transform=transform) #was transform = train_tr
train_loader = torch.utils.data.DataLoader(train_set, batch_size=Batch_Size, shuffle=True)

test_set = torchvision.datasets.CIFAR10("Data", download=True, train=False, transform=transform) # was test_tr
test_loader = torch.utils.data.DataLoader(test_set, batch_size=Batch_Size, shuffle=False)

print(f"Training set shape: {train_set.data.shape}")
print(f"Testing set shape: {test_set.data.shape}")
print(f"Classes: {train_set.classes}")

class CIFAR10_nn(nn.Module):
  def __init__(self):
    super(CIFAR10_nn, self).__init__()

    #3 input channels, 32 output feature maps, 3x3 filter size, padding keeps image dimensions the same
    self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
    self.conv3 = nn.Conv2d(64, 128, 3, padding=1) #New conv layer

    #pooling layers reduce image size, takes max value in each 2x2 region
    self.pool = nn.MaxPool2d(2, 2)

    #fully connected layers connect every input to every output
    self.fc1 = nn.Linear(128 * 4 * 4, 512) #adjusted input size
    self.fc2 = nn.Linear(512, 256)
    self.fc3 = nn.Linear(256, 10)

    #Dropout randomly turns off 25% of neurons during training
    #--> Prevents nn from memorising the training data
    self.dropout = nn.Dropout(0.25)

  #Defines how data flows through the network
  def forward(self, x):
    
    #1. 1st conv layer -> reLU activation -> pooling
    x = self.pool(F.relu(self.conv1(x))) #Img size: 32x32 -> 16x16

    #2. 2nd conv layer -> reLU activation -> pooling
    x = self.pool(F.relu(self.conv2(x))) #Img size: 16x16 -> 8x8

    #3. 3rd conv layer -> reLU activation -> pooling 
    x = self.pool(F.relu(self.conv3(x))) #Img size: 8x8 -> 4x4

    #4. Flatten 3D feature maps into a 1D vector
    x = x.view(-1, 128 * 4 * 4) #Adjusted values for new size

    #5. 1st fully connected layer -> ReLU -> dropout
    x = self.dropout(F.relu(self.fc1(x)))

    #6. 2nd fully connected layer -> reLU -> dropout
    x = self.dropout(F.relu(self.fc2(x)))

    #7. Final outout layer
    x = self.fc3(x)
      
    return x

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

net = CIFAR10_nn()
print(net)

net.to(device)

criterion = nn.CrossEntropyLoss()
optimiser = optim.Adam(net.parameters(), lr=0.001)

train_losses = []
accuracies = []

for epoch in range(EPOCHS):
  running_loss = 0.0
  net.train()
  for i, data in enumerate(train_loader, 0):
    inputs, labels = data
    inputs, labels = inputs.to(device), labels.to(device)

    optimiser.zero_grad()
    outputs = net(inputs)
    loss = criterion(outputs, labels)
    loss.backward()
    optimiser.step()

    running_loss += loss.item()

  epoch_loss = running_loss / len(train_loader)
  train_losses.append(epoch_loss)

  #Evaluation: 
  correct = 0
  total = 0
  
  net.eval()  # Set model to evaluation mode
  
  with torch.no_grad():  # No need to track gradients
    for data in test_loader:
      images, labels = data
      images, labels = images.to(device), labels.to(device)
      outputs = net(images)
      _, predicted = torch.max(outputs.data, 1)
      correct += (predicted == labels).sum().item()
      total += labels.size(0)
  
  accuracy = 100 * correct / total  # Should now be <= 100%
  accuracies.append(accuracy)
  print(f'Epoch {epoch+1}/{EPOCHS} - Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%')


#Plot:
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(accuracies, label='Test Accuracy')
plt.ylim(0, 100)
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Test Accuracy')
plt.legend()

plt.tight_layout()
plt.show()
